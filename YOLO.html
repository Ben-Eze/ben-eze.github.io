<!DOCTYPE html>
<html>
  <head>
    <title>YOLO</title>
    <link rel="stylesheet" href="css/root.css">
    <link rel="stylesheet" href="css/nav.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@100..900&display=swap" rel="stylesheet">
  </head>
  
  <body>
    <nav>
      <div class="nav-links">
        <div class="left-nav">
          <a class="nav-active-button" href="index.html">
            Ben <strong>Eze</strong>
          </a>
          <a class="nav-inactive-button" href="index.html#projects">
            Projects
          </a>
        </div>
        <div class="right-nav">
          <a class="nav-active-button" href="index.html#contact">
            Contact</strong>
          </a>
          <a class="nav-inactive-button" href="assets/PDFs/CV.pdf" target="_blank">
            CV
          </a>
        </div>
      </div>
    </nav>
    <section id="YOLO-project">
      <div class="typewriter"><div><h1>YOLO</h1></div></div>
      <h3>
        Intro
      </h3>
      <h4>
        The YOLO algorithm has become synonomous with object detection since the paper was published in 2015. Instead of previous algorithms which try to repurpose classification models on various portions of the image to attempt to find bounding boxes, the YOLO algorithm generates bounding boxes and class probabilities all in one 'glance', hence the name.
      </h4>
      <h3>
        Key Terms
      </h3>
      <li>IOL (intersection over union): this is the intersected area divided by the union area between two bounding boxes. This is used to measure how well the ground truth and the predicted bounded boxes overlap</li>
      <li>Confidence: This is the product of the probability score and the IOU of </li>
    </section>
  </body>
</html>