<!DOCTYPE html>
<html>
  <head>
    <title>Misc AI</title>
    <link rel="stylesheet" href="css/root.css">
    <link rel="stylesheet" href="css/nav.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@100..900&display=swap" rel="stylesheet">
  </head>
  
  <body>
    <nav>
      <div class="nav-links">
        <div class="left-nav">
          <a class="nav-active-button" href="index.html">
            Ben <strong>Eze</strong>
          </a>
          <a class="nav-inactive-button" href="index.html#projects">
            Projects
          </a>
        </div>
        <div class="right-nav">
          <a class="nav-active-button" href="index.html#contact">
            Contact</strong>
          </a>
          <a class="nav-inactive-button" href="assets/PDFs/CV.pdf" target="_blank">
            CV
          </a>
        </div>
      </div>
    </nav>
    <section id="misc-AI-project">
      <div class="typewriter"><div><h1 class="char20">Other AI/ML Projects</h1></div></div>
      <h3>
        Pytorch
      </h3>
      <h4>
        Pytorch is one of, if not the most popular ML libraries in python, offering a vast amount of tools for deep learning, whilst also being flexible and easy to use. It is used at companies such as OpenAI, Tesla and Facebook, and I opted to use this library for my projects.
      </h4>
      <h4>
        My first project was a simple digit classification model. Though it is a simple and generally considered a 'solved' problem, it is a great introduction to many fundamental concepts, such as backpropagation and loss functions, and one can easily compare different model architectures on their performance to start to develop an intuition for what works well. Given the experimental nature of ML, I was careful to develop good practices around saving models and their performance for easy comparison. The aim was to have as few hyperparameters within the code, instead storing them in .json 'config' files.
        <h4>
          To see the code for this project, click <a href="https://www.google.com/">here</a>. A few things that one can investigate include...
          <ol>
            <li>CNN vs multi-layer perceptron (MLP) architecture</li>
            <li>How small and fast can you make a model?</li>
            <li>How to prevent overfitting?</li>
          <li>How to prevent overfitting?</li>
          </ol>
        </h4>
        </h4>
        <h3>
        Visualizations
        </h3>
        <h4>
        To make the insights from my projects more accessible, I have included several visualizations. These graphics help to illustrate the performance of different models, the impact of various hyperparameters, and the overall training process.
        </h4>
        <div class="visualization">
        <img src="assets/images/model_comparison.png" alt="Model Comparison">
        <p>Comparison of CNN and MLP architectures on digit classification task.</p>
        </div>
        <div class="visualization">
        <img src="assets/images/training_process.png" alt="Training Process">
        <p>Visualization of the training process, showing loss and accuracy over epochs.</p>
        </div>
      </section>
        </h4>
      </h4>
    </section>
  </body>
</html>